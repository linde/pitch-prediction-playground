{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# good references\n",
    "# https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "# https://www.tensorflow.org/tutorials/load_data/csv\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO there is a numpy util to get files from within tgz's and zips\n",
    "##!curl -s 'https://storage.googleapis.com/0x19f.com/media/kaggle-mlb-pitch-data-2015-2018.tgz' | tar xz\n",
    "\n",
    "BASEBALL_FILES_BASE = os.getcwd() + \"/kaggle-mlb-pitch-data-2015-2018/\"\n",
    "BASEBALL_FILES_BASE = BASEBALL_FILES_BASE + \"2019_\"  # just look at 2019 to speed things up\n",
    "\n",
    "pitches = pd.read_csv(BASEBALL_FILES_BASE + 'pitches.csv')\n",
    "atbats = pd.read_csv(BASEBALL_FILES_BASE + 'atbats.csv')\n",
    "\n",
    "df = pd.merge(pitches, atbats, how='inner', on='ab_id')\n",
    "\n",
    "df = df[[\n",
    "    # situation stuff\n",
    "    \"ab_id\", \"inning\", \"top\", \"outs\", \"on_1b\", \"on_2b\", \"on_3b\",\n",
    "\n",
    "    # matchup\n",
    "    \"pitcher_id\", \"p_throws\", \"batter_id\", \"stand\",\n",
    "\n",
    "    # specific pitch state\n",
    "    \"pitch_num\", \"b_count\", \"s_count\",\n",
    "    # TODO need to add running total of pitches for the current pitcher, and maybe strike percentage\n",
    "    # TODO add the previous n pitches before and their code outcome\n",
    "    # \n",
    "    \n",
    "    # this is the label we're trying to predict\n",
    "    \"code\",\n",
    "    \"pitch_type\",\n",
    "    # TODO also make the label have the location. not just FF (fourseam fastball, but also high inside)\n",
    "]]\n",
    "\n",
    "# remove anything without values, hard to have defaults\n",
    "# df = df.dropna(subset=['pitch_type', 'code'])\n",
    "df = df.dropna()\n",
    "\n",
    "## this is our current target label TODO make this categorical \n",
    "df[\"is_fastball\"] = np.where(df[\"pitch_type\"].isin([\"FC\",\"FF\",\"FT\",]), 1, 0)\n",
    "\n",
    "# get appropriate types. \n",
    "# TODO prob can use a schema on the CSV read to get only the columns we're after, alias them to be more\n",
    "#      useful, and cast to the right type\n",
    "# TODO consider to_ordinal for cumulative things maybe? inning, outs, pitch_num, b_count, s_count\n",
    "\n",
    "# TODO there is a numpy util to get files from within tgz's and zips\n",
    "##!curl -s 'https://storage.googleapis.com/0x19f.com/media/kaggle-mlb-pitch-data-2015-2018.tgz' | tar xz\n",
    "\n",
    "BASEBALL_FILES_BASE = os.getcwd() + \"/kaggle-mlb-pitch-data-2015-2018/\"\n",
    "BASEBALL_FILES_BASE = BASEBALL_FILES_BASE + \"2019_\"  # just look at 2019 to speed things up\n",
    "\n",
    "\n",
    "pitches = pd.read_csv(BASEBALL_FILES_BASE + 'pitches.csv')\n",
    "atbats = pd.read_csv(BASEBALL_FILES_BASE + 'atbats.csv')\n",
    "\n",
    "df = pd.merge(pitches, atbats, how='inner', on='ab_id')\n",
    "\n",
    "df = df[[\n",
    "    # situation stuff\n",
    "    \"ab_id\", \"inning\", \"top\", \"outs\", \n",
    "    \n",
    "    # would get baserunner stuff but these were all zero.\n",
    "    #\"on_1b\", \"on_2b\", \"on_3b\",\n",
    "\n",
    "    # matchup\n",
    "    \"pitcher_id\", \"p_throws\", \"batter_id\", \"stand\",\n",
    "\n",
    "    # TODO add catcher, team\n",
    "    # specific pitch state\n",
    "    \"pitch_num\", \"b_count\", \"s_count\",\n",
    "    # TODO p0: multi hot encode the count\n",
    "    # TODO need to add running total of pitches for the current pitcher, and maybe strike percentage\n",
    "    # TODO add the previous n pitches before and their code outcome\n",
    "    # \n",
    "    \n",
    "    # this is the label we're trying to predict\n",
    "    # \"code\",\n",
    "    \"pitch_type\",\n",
    "    # TODO also make the label have the location. not just FF (fourseam fastball, but also high inside)\n",
    "]]\n",
    "\n",
    "# remove anything without values, hard to have defaults\n",
    "df = df.dropna()\n",
    "\n",
    "## this is our current target label TODO make this categorical \n",
    "df[\"is_fastball\"] = np.where(df[\"pitch_type\"].isin([\"FC\",\"FF\",\"FT\",]), 1, 0)\n",
    "\n",
    "# get appropriate types. \n",
    "# TODO prob can use a schema on the CSV read to get only the columns we're after, alias them to be more\n",
    "#      useful, and cast to the right type\n",
    "# TODO consider to_ordinal for cumulative things maybe? inning, outs, pitch_num, b_count, s_count\n",
    "\n",
    "df = df.astype({\n",
    "    # string features\n",
    "    'p_throws': 'string',\n",
    "    'stand': 'string',\n",
    "\n",
    "    # small card numeric features\n",
    "    'inning': 'int8',\n",
    "    'top': 'int8',\n",
    "    'outs': 'int8',\n",
    "\n",
    "    'pitch_num': 'int8',\n",
    "    'b_count': 'int8',\n",
    "    's_count': 'int8',\n",
    "\n",
    "    # player identifiers, treat them as strings so we dont scale them\n",
    "    'pitcher_id': 'string', \n",
    "    'batter_id': 'string',\n",
    "  })\n",
    "\n",
    "# drop ab_id now that join has occured, not a useful feature; also pitch_type since we're doing is_fastball\n",
    "df = df.drop(['ab_id', 'pitch_type'], axis=1)\n",
    "\n",
    "# TODO remove this truncation when solid\n",
    "df = df.truncate(after=100*1000)\n",
    "\n",
    "\n",
    "pitch_features = df.copy()\n",
    "pitch_labels = pitch_features.pop('is_fastball')\n",
    "\n",
    "print(pitch_features.info())\n",
    "print(pitch_features.shape)\n",
    "\n",
    "pitch_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feature_inputs, processed_inputs = {}, []\n",
    "\n",
    "for name, col in pitch_features.items():\n",
    "    print(\"processing: %s ...\" % name)\n",
    "    col_type_str = str(col.dtype)\n",
    "    tf_type_for_col = tf.as_dtype(col_type_str)\n",
    "\n",
    "    # first create the feature's input and collect into feature_inputs\n",
    "    col_input = tf.keras.Input(shape=(1,), name=name, dtype=tf_type_for_col)\n",
    "    feature_inputs[name] = col_input\n",
    "\n",
    "    # next, normalize the feature values and collect them in feature_normalizers\n",
    "    if col_type_str in [\"string\"]:       \n",
    "        feature_lookup = layers.StringLookup(vocabulary=np.unique(pitch_features[name]))\n",
    "        one_hot = layers.CategoryEncoding(num_tokens=feature_lookup.vocabulary_size(), output_mode=\"one_hot\")\n",
    "\n",
    "        col_values_from_lookup = feature_lookup(col_input)\n",
    "        normalizer = one_hot(col_values_from_lookup)\n",
    "\n",
    "    else:  # TODO should prob do a better job of figuring out numerics\n",
    "        norm = layers.Normalization()\n",
    "        norm.adapt(col)\n",
    "        normalizer = norm(col_input)\n",
    "        \n",
    "    # here we append the normalizer from the respective types\n",
    "    processed_inputs.append(normalizer)\n",
    "\n",
    "feature_inputs, len(processed_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_inputs = layers.Concatenate()(processed_inputs)\n",
    "pitch_preprocessing = tf.keras.Model(feature_inputs, all_processed_inputs)\n",
    "\n",
    "# tf.keras.utils.plot_model(model = pitch_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq_model = tf.keras.Sequential([\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(1),\n",
    "  ])\n",
    "\n",
    "\n",
    "preprossesed_inputs = pitch_preprocessing(feature_inputs)\n",
    "result = seq_model(preprossesed_inputs)\n",
    "pitch_model = tf.keras.Model(feature_inputs, result)\n",
    "\n",
    "pitch_model.compile(\"adam\", \"binary_crossentropy\", run_eagerly=True, metrics=[\"accuracy\"])\n",
    "\n",
    "pitch_features_dict = {\n",
    "  name: np.array(value) for name, value in pitch_features.items()\n",
    "}\n",
    "pitch_model.fit(x=pitch_features_dict, y=pitch_labels, epochs=100, batch_size=30*1000)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
