{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 23:01:34.923427: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-27 23:01:34.950541: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-27 23:01:34.951868: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-27 23:01:35.584812: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# good references\n",
    "# https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "# https://www.tensorflow.org/tutorials/load_data/csv\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 98972 entries, 0 to 100000\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   inning      98972 non-null  int8  \n",
      " 1   top         98972 non-null  int8  \n",
      " 2   outs        98972 non-null  int8  \n",
      " 3   on_1b       98972 non-null  int8  \n",
      " 4   on_2b       98972 non-null  int8  \n",
      " 5   on_3b       98972 non-null  int8  \n",
      " 6   pitcher_id  98972 non-null  int64 \n",
      " 7   p_throws    98972 non-null  string\n",
      " 8   batter_id   98972 non-null  int64 \n",
      " 9   stand       98972 non-null  string\n",
      " 10  pitch_num   98972 non-null  int8  \n",
      " 11  b_count     98972 non-null  int8  \n",
      " 12  s_count     98972 non-null  int8  \n",
      "dtypes: int64(2), int8(9), string(2)\n",
      "memory usage: 4.6 MB\n",
      "None\n",
      "(98972, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inning</th>\n",
       "      <th>top</th>\n",
       "      <th>outs</th>\n",
       "      <th>on_1b</th>\n",
       "      <th>on_2b</th>\n",
       "      <th>on_3b</th>\n",
       "      <th>pitcher_id</th>\n",
       "      <th>p_throws</th>\n",
       "      <th>batter_id</th>\n",
       "      <th>stand</th>\n",
       "      <th>pitch_num</th>\n",
       "      <th>b_count</th>\n",
       "      <th>s_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>571666</td>\n",
       "      <td>R</td>\n",
       "      <td>594777</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>571666</td>\n",
       "      <td>R</td>\n",
       "      <td>545361</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>571666</td>\n",
       "      <td>R</td>\n",
       "      <td>545361</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>571666</td>\n",
       "      <td>R</td>\n",
       "      <td>545361</td>\n",
       "      <td>R</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>571666</td>\n",
       "      <td>R</td>\n",
       "      <td>545361</td>\n",
       "      <td>R</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inning  top  outs  on_1b  on_2b  on_3b  pitcher_id p_throws  batter_id  \\\n",
       "0       1    1     0      0      0      0      571666        R     594777   \n",
       "1       1    1     1      0      0      0      571666        R     545361   \n",
       "2       1    1     1      0      0      0      571666        R     545361   \n",
       "3       1    1     1      0      0      0      571666        R     545361   \n",
       "4       1    1     1      0      0      0      571666        R     545361   \n",
       "\n",
       "  stand  pitch_num  b_count  s_count  \n",
       "0     L          1        0        0  \n",
       "1     R          1        0        0  \n",
       "2     R          2        0        0  \n",
       "3     R          3        0        1  \n",
       "4     R          4        1        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO there is a numpy util to get files from within tgz's and zips\n",
    "##!curl -s 'https://storage.googleapis.com/0x19f.com/media/kaggle-mlb-pitch-data-2015-2018.tgz' | tar xz\n",
    "\n",
    "BASEBALL_FILES_BASE = os.getcwd() + \"/kaggle-mlb-pitch-data-2015-2018/\"\n",
    "BASEBALL_FILES_BASE = BASEBALL_FILES_BASE + \"2019_\"  # just look at 2019 to speed things up\n",
    "\n",
    "\n",
    "pitches = pd.read_csv(BASEBALL_FILES_BASE + 'pitches.csv')\n",
    "atbats = pd.read_csv(BASEBALL_FILES_BASE + 'atbats.csv')\n",
    "\n",
    "df = pd.merge(pitches, atbats, how='inner', on='ab_id')\n",
    "\n",
    "df = df[[\n",
    "    # situation stuff\n",
    "    \"ab_id\", \"inning\", \"top\", \"outs\", \"on_1b\", \"on_2b\", \"on_3b\",\n",
    "\n",
    "    # matchup\n",
    "    \"pitcher_id\", \"p_throws\", \"batter_id\", \"stand\",\n",
    "\n",
    "    # specific pitch state\n",
    "    \"pitch_num\", \"b_count\", \"s_count\",\n",
    "    # TODO need to add running total of pitches for the current pitcher, and maybe strike percentage\n",
    "    # TODO add the previous n pitches before and their code outcome\n",
    "    # \n",
    "    \n",
    "    # this is the label we're trying to predict\n",
    "    \"code\",\n",
    "    \"pitch_type\",\n",
    "    # TODO also make the label have the location. not just FF (fourseam fastball, but also high inside)\n",
    "]]\n",
    "\n",
    "# remove anything without values, hard to have defaults\n",
    "# df = df.dropna(subset=['pitch_type', 'code'])\n",
    "df = df.dropna()\n",
    "\n",
    "## this is our current target label TODO make this categorical \n",
    "df[\"is_fastball\"] = np.where(df[\"pitch_type\"].isin([\"FC\",\"FF\",\"FT\",]), 1, 0)\n",
    "\n",
    "# get appropriate types. \n",
    "# TODO prob can use a schema on the CSV read to get only the columns we're after, alias them to be more\n",
    "#      useful, and cast to the right type\n",
    "# TODO consider to_ordinal for cumulative things maybe? inning, outs, pitch_num, b_count, s_count\n",
    "\n",
    "# TODO there is a numpy util to get files from within tgz's and zips\n",
    "##!curl -s 'https://storage.googleapis.com/0x19f.com/media/kaggle-mlb-pitch-data-2015-2018.tgz' | tar xz\n",
    "\n",
    "BASEBALL_FILES_BASE = os.getcwd() + \"/kaggle-mlb-pitch-data-2015-2018/\"\n",
    "BASEBALL_FILES_BASE = BASEBALL_FILES_BASE + \"2019_\"  # just look at 2019 to speed things up\n",
    "\n",
    "\n",
    "pitches = pd.read_csv(BASEBALL_FILES_BASE + 'pitches.csv')\n",
    "atbats = pd.read_csv(BASEBALL_FILES_BASE + 'atbats.csv')\n",
    "\n",
    "df = pd.merge(pitches, atbats, how='inner', on='ab_id')\n",
    "\n",
    "df = df[[\n",
    "    # situation stuff\n",
    "    \"ab_id\", \"inning\", \"top\", \"outs\", \"on_1b\", \"on_2b\", \"on_3b\",\n",
    "\n",
    "    # matchup\n",
    "    \"pitcher_id\", \"p_throws\", \"batter_id\", \"stand\",\n",
    "\n",
    "    # specific pitch state\n",
    "    \"pitch_num\", \"b_count\", \"s_count\",\n",
    "    # TODO p0: multi hot encode the count\n",
    "    # TODO need to add running total of pitches for the current pitcher, and maybe strike percentage\n",
    "    # TODO add the previous n pitches before and their code outcome\n",
    "    # \n",
    "    \n",
    "    # this is the label we're trying to predict\n",
    "    \"code\",\n",
    "    \"pitch_type\",\n",
    "    # TODO also make the label have the location. not just FF (fourseam fastball, but also high inside)\n",
    "]]\n",
    "\n",
    "# remove anything without values, hard to have defaults\n",
    "# df = df.dropna(subset=['pitch_type', 'code'])\n",
    "df = df.dropna()\n",
    "\n",
    "## this is our current target label TODO make this categorical \n",
    "df[\"is_fastball\"] = np.where(df[\"pitch_type\"].isin([\"FC\",\"FF\",\"FT\",]), 1, 0)\n",
    "\n",
    "# get appropriate types. \n",
    "# TODO prob can use a schema on the CSV read to get only the columns we're after, alias them to be more\n",
    "#      useful, and cast to the right type\n",
    "# TODO consider to_ordinal for cumulative things maybe? inning, outs, pitch_num, b_count, s_count\n",
    "\n",
    "\n",
    "# TODO consider using ints and normalizing them instead of floats for innnigs etc\n",
    "\n",
    "df = df.astype({\n",
    "    # string features\n",
    "    'p_throws': 'string',\n",
    "    'stand': 'string',\n",
    "\n",
    "    # small card numeric features\n",
    "    'inning': 'int8',\n",
    "    'top': 'int8',\n",
    "    'outs': 'int8',\n",
    "    'on_1b': 'int8',\n",
    "    'on_2b': 'int8',\n",
    "    'on_3b': 'int8',\n",
    "    'pitch_num': 'int8',\n",
    "    'b_count': 'int8',\n",
    "    's_count': 'int8',\n",
    "\n",
    "    # player identifiers\n",
    "    'pitcher_id': 'int64', \n",
    "    'batter_id': 'int64',\n",
    "  })\n",
    "\n",
    "\n",
    "# drop ab_id now that join has occured, not a useful feature\n",
    "df = df.drop(['ab_id', \"code\",\"pitch_type\"], axis=1)\n",
    "\n",
    "# TODO remove this truncation when solid\n",
    "df = df.truncate(after=100*1000)\n",
    "\n",
    "\n",
    "pitch_features = df.copy()\n",
    "pitch_labels = pitch_features.pop('is_fastball')\n",
    "\n",
    "print(pitch_features.info())\n",
    "print(pitch_features.shape)\n",
    "\n",
    "pitch_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: inning ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 23:01:53.890011: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: top ...\n",
      "processing: outs ...\n",
      "processing: on_1b ...\n",
      "processing: on_2b ...\n",
      "processing: on_3b ...\n",
      "processing: pitcher_id ...\n",
      "processing: p_throws ...\n",
      "processing: batter_id ...\n",
      "processing: stand ...\n",
      "processing: pitch_num ...\n",
      "processing: b_count ...\n",
      "processing: s_count ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'inning': <KerasTensor: shape=(None, 1) dtype=int8 (created by layer 'inning')>,\n",
       "  'top': <KerasTensor: shape=(None, 1) dtype=int8 (created by layer 'top')>,\n",
       "  'outs': <KerasTensor: shape=(None, 1) dtype=int8 (created by layer 'outs')>,\n",
       "  'on_1b': <KerasTensor: shape=(None, 1) dtype=int8 (created by layer 'on_1b')>,\n",
       "  'on_2b': <KerasTensor: shape=(None, 1) dtype=int8 (created by layer 'on_2b')>,\n",
       "  'on_3b': <KerasTensor: shape=(None, 1) dtype=int8 (created by layer 'on_3b')>,\n",
       "  'pitcher_id': <KerasTensor: shape=(None, 1) dtype=int64 (created by layer 'pitcher_id')>,\n",
       "  'p_throws': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'p_throws')>,\n",
       "  'batter_id': <KerasTensor: shape=(None, 1) dtype=int64 (created by layer 'batter_id')>,\n",
       "  'stand': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'stand')>,\n",
       "  'pitch_num': <KerasTensor: shape=(None, 1) dtype=int8 (created by layer 'pitch_num')>,\n",
       "  'b_count': <KerasTensor: shape=(None, 1) dtype=int8 (created by layer 'b_count')>,\n",
       "  's_count': <KerasTensor: shape=(None, 1) dtype=int8 (created by layer 's_count')>},\n",
       " 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "feature_inputs, processed_inputs = {}, []\n",
    "\n",
    "for name, col in pitch_features.items():\n",
    "    print(\"processing: %s ...\" % name)\n",
    "    col_type_str = str(col.dtype)\n",
    "    tf_type_for_col = tf.as_dtype(col_type_str)\n",
    "\n",
    "    # first create the feature's input and collect into feature_inputs\n",
    "    col_input = tf.keras.Input(shape=(1,), name=name, dtype=tf_type_for_col)\n",
    "    feature_inputs[name] = col_input\n",
    "\n",
    "    # next, normalize the feature values and collect them in feature_normalizers\n",
    "    if col_type_str == \"string\":       \n",
    "        feature_lookup = layers.StringLookup(vocabulary=np.unique(pitch_features[name]))\n",
    "        one_hot = layers.CategoryEncoding(num_tokens=feature_lookup.vocabulary_size(), output_mode=\"one_hot\")\n",
    "\n",
    "        col_values_from_lookup = feature_lookup(col_input)\n",
    "        normalizer = one_hot(col_values_from_lookup)\n",
    "\n",
    "    else:  # TODO should prob do a better job of figuring out numerics\n",
    "        norm = layers.Normalization()\n",
    "        norm.adapt(col)\n",
    "        normalizer = norm(col_input)\n",
    "        \n",
    "    # here we append the normalizer from the respective types\n",
    "    processed_inputs.append(normalizer)\n",
    "\n",
    "feature_inputs, len(processed_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_inputs = layers.Concatenate()(processed_inputs)\n",
    "pitch_preprocessing = tf.keras.Model(feature_inputs, all_processed_inputs)\n",
    "\n",
    "# tf.keras.utils.plot_model(model = pitch_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.9412 - accuracy: 0.5105\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.7434 - accuracy: 0.5169\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.7209 - accuracy: 0.5181\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.7153 - accuracy: 0.5234\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.7111 - accuracy: 0.5293\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.7044 - accuracy: 0.5285\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6997 - accuracy: 0.5276\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6966 - accuracy: 0.5285\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6947 - accuracy: 0.5305\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6939 - accuracy: 0.5318\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.6924 - accuracy: 0.5336\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.6915 - accuracy: 0.5362\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.6902 - accuracy: 0.5372\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6891 - accuracy: 0.5390\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6884 - accuracy: 0.5407\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6878 - accuracy: 0.5421\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6874 - accuracy: 0.5434\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6869 - accuracy: 0.5445\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6865 - accuracy: 0.5455\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.6860 - accuracy: 0.5453\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.6856 - accuracy: 0.5460\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6853 - accuracy: 0.5464\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.6849 - accuracy: 0.5471\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.6846 - accuracy: 0.5479\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.6844 - accuracy: 0.5480\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.6841 - accuracy: 0.5489\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.6838 - accuracy: 0.5490\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.6836 - accuracy: 0.5495\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.6834 - accuracy: 0.5502\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6831 - accuracy: 0.5505\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.6829 - accuracy: 0.5512\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.6827 - accuracy: 0.5516\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.6825 - accuracy: 0.5523\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.6824 - accuracy: 0.5530\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.6822 - accuracy: 0.5524\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.6820 - accuracy: 0.5532\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.6818 - accuracy: 0.5535\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.6816 - accuracy: 0.5538\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.6815 - accuracy: 0.5539\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.6813 - accuracy: 0.5544\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.6812 - accuracy: 0.5543\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.6810 - accuracy: 0.5552\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.6809 - accuracy: 0.5547\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.6807 - accuracy: 0.5557\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6806 - accuracy: 0.5560\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6805 - accuracy: 0.5564\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.6803 - accuracy: 0.5575\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.6802 - accuracy: 0.5574\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.6801 - accuracy: 0.5577\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.6799 - accuracy: 0.5576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x784c9af90760>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "seq_model = tf.keras.Sequential([\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"relu\"),\n",
    "  ])\n",
    "\n",
    "\n",
    "preprossesed_inputs = pitch_preprocessing(feature_inputs)\n",
    "result = seq_model(preprossesed_inputs)\n",
    "pitch_model = tf.keras.Model(feature_inputs, result)\n",
    "\n",
    "pitch_model.compile(\"adam\", \"binary_crossentropy\", run_eagerly=True, metrics=[\"accuracy\"])\n",
    "\n",
    "pitch_features_dict = {\n",
    "  name: np.array(value) for name, value in pitch_features.items()\n",
    "}\n",
    "pitch_model.fit(x=pitch_features_dict, y=pitch_labels, epochs=500, batch_size=20*1000)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
