{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 22:41:44.811139: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-26 22:41:44.950228: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-26 22:41:44.952460: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-26 22:41:46.351462: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49774 entries, 0 to 50000\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   inning       49774 non-null  float64\n",
      " 1   top          49774 non-null  float64\n",
      " 2   outs         49774 non-null  float64\n",
      " 3   on_1b        49774 non-null  float64\n",
      " 4   on_2b        49774 non-null  float64\n",
      " 5   on_3b        49774 non-null  float64\n",
      " 6   pitcher_id   49774 non-null  int64  \n",
      " 7   p_throws     49774 non-null  string \n",
      " 8   batter_id    49774 non-null  int64  \n",
      " 9   stand        49774 non-null  string \n",
      " 10  pitch_num    49774 non-null  float64\n",
      " 11  b_count      49774 non-null  float64\n",
      " 12  s_count      49774 non-null  float64\n",
      " 13  is_fastball  49774 non-null  int64  \n",
      "dtypes: float64(9), int64(3), string(2)\n",
      "memory usage: 5.7 MB\n",
      "None\n",
      "(49774, 14)\n"
     ]
    }
   ],
   "source": [
    "# TODO there is a numpy util to get files from within tgz's and zips\n",
    "##!curl -s 'https://storage.googleapis.com/0x19f.com/media/kaggle-mlb-pitch-data-2015-2018.tgz' | tar xz\n",
    "\n",
    "BASEBALL_FILES_BASE = os.getcwd() + \"/kaggle-mlb-pitch-data-2015-2018/\"\n",
    "BASEBALL_FILES_BASE = BASEBALL_FILES_BASE + \"2019_\"  # just look at 2019 to speed things up\n",
    "\n",
    "\n",
    "pitches = pd.read_csv(BASEBALL_FILES_BASE + 'pitches.csv')\n",
    "atbats = pd.read_csv(BASEBALL_FILES_BASE + 'atbats.csv')\n",
    "\n",
    "df = pd.merge(pitches, atbats, how='inner', on='ab_id')\n",
    "\n",
    "df = df[[\n",
    "    # situation stuff\n",
    "    \"ab_id\", \"inning\", \"top\", \"outs\", \"on_1b\", \"on_2b\", \"on_3b\",\n",
    "\n",
    "    # matchup\n",
    "    \"pitcher_id\", \"p_throws\", \"batter_id\", \"stand\",\n",
    "\n",
    "    # specific pitch state\n",
    "    \"pitch_num\", \"b_count\", \"s_count\",\n",
    "    # TODO need to add running total of pitches for the current pitcher, and maybe strike percentage\n",
    "    # TODO add the previous n pitches before and their code outcome\n",
    "    # \n",
    "    \n",
    "    # this is the label we're trying to predict\n",
    "    \"code\",\n",
    "    \"pitch_type\",\n",
    "    # TODO also make the label have the location. not just FF (fourseam fastball, but also high inside)\n",
    "]]\n",
    "\n",
    "# remove anything without values, hard to have defaults\n",
    "# df = df.dropna(subset=['pitch_type', 'code'])\n",
    "df = df.dropna()\n",
    "\n",
    "## this is our current target label TODO make this categorical \n",
    "df[\"is_fastball\"] = np.where(df[\"pitch_type\"].isin([\"FC\",\"FF\",\"FT\",]), 1, 0)\n",
    "\n",
    "# get appropriate types. \n",
    "# TODO prob can use a schema on the CSV read to get only the columns we're after, alias them to be more\n",
    "#      useful, and cast to the right type\n",
    "# TODO consider to_ordinal for cumulative things maybe? inning, outs, pitch_num, b_count, s_count\n",
    "\n",
    "# TODO there is a numpy util to get files from within tgz's and zips\n",
    "##!curl -s 'https://storage.googleapis.com/0x19f.com/media/kaggle-mlb-pitch-data-2015-2018.tgz' | tar xz\n",
    "\n",
    "BASEBALL_FILES_BASE = os.getcwd() + \"/kaggle-mlb-pitch-data-2015-2018/\"\n",
    "BASEBALL_FILES_BASE = BASEBALL_FILES_BASE + \"2019_\"  # just look at 2019 to speed things up\n",
    "\n",
    "\n",
    "pitches = pd.read_csv(BASEBALL_FILES_BASE + 'pitches.csv')\n",
    "atbats = pd.read_csv(BASEBALL_FILES_BASE + 'atbats.csv')\n",
    "\n",
    "df = pd.merge(pitches, atbats, how='inner', on='ab_id')\n",
    "\n",
    "df = df[[\n",
    "    # situation stuff\n",
    "    \"ab_id\", \"inning\", \"top\", \"outs\", \"on_1b\", \"on_2b\", \"on_3b\",\n",
    "\n",
    "    # matchup\n",
    "    \"pitcher_id\", \"p_throws\", \"batter_id\", \"stand\",\n",
    "\n",
    "    # specific pitch state\n",
    "    \"pitch_num\", \"b_count\", \"s_count\",\n",
    "    # TODO need to add running total of pitches for the current pitcher, and maybe strike percentage\n",
    "    # TODO add the previous n pitches before and their code outcome\n",
    "    # \n",
    "    \n",
    "    # this is the label we're trying to predict\n",
    "    \"code\",\n",
    "    \"pitch_type\",\n",
    "    # TODO also make the label have the location. not just FF (fourseam fastball, but also high inside)\n",
    "]]\n",
    "\n",
    "# remove anything without values, hard to have defaults\n",
    "# df = df.dropna(subset=['pitch_type', 'code'])\n",
    "df = df.dropna()\n",
    "\n",
    "## this is our current target label TODO make this categorical \n",
    "df[\"is_fastball\"] = np.where(df[\"pitch_type\"].isin([\"FC\",\"FF\",\"FT\",]), 1, 0)\n",
    "\n",
    "# get appropriate types. \n",
    "# TODO prob can use a schema on the CSV read to get only the columns we're after, alias them to be more\n",
    "#      useful, and cast to the right type\n",
    "# TODO consider to_ordinal for cumulative things maybe? inning, outs, pitch_num, b_count, s_count\n",
    "\n",
    "\n",
    "# TODO consider using ints and normalizing them instead of floats for innnigs etc\n",
    "\n",
    "df = df.astype({\n",
    "    'p_throws': 'string',\n",
    "    'stand': 'string',\n",
    "  })\n",
    "\n",
    "\n",
    "# drop ab_id now that join has occured, not a useful feature\n",
    "df = df.drop(['ab_id', \"code\",\"pitch_type\"], axis=1)\n",
    "\n",
    "# TODO remove this truncation when solid\n",
    "df = df.truncate(after=50000)\n",
    "\n",
    "print(df.info())\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features = df.copy()\n",
    "pitch_labels = pitch_features.pop('is_fastball')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inning': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'inning')>,\n",
       " 'top': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'top')>,\n",
       " 'outs': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'outs')>,\n",
       " 'on_1b': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'on_1b')>,\n",
       " 'on_2b': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'on_2b')>,\n",
       " 'on_3b': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'on_3b')>,\n",
       " 'pitcher_id': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'pitcher_id')>,\n",
       " 'p_throws': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'p_throws')>,\n",
       " 'batter_id': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'batter_id')>,\n",
       " 'stand': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'stand')>,\n",
       " 'pitch_num': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'pitch_num')>,\n",
       " 'b_count': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'b_count')>,\n",
       " 's_count': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 's_count')>}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inputs = {}\n",
    "\n",
    "for name, col in pitch_features.items():\n",
    "  if str(col.dtype) == \"string\":\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_inputs = {\n",
    "  name:input for name,input in inputs.items() if input.dtype==tf.float32\n",
    "}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = layers.Normalization()\n",
    "norm.adapt(np.array(pitch_features[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "preprocessed_inputs = [all_numeric_inputs]\n",
    "\n",
    "for name, input in inputs.items():\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "\n",
    "  print(\"processing %s\" % name)\n",
    "  \n",
    "  lookup = layers.StringLookup(vocabulary=np.unique(pitch_features[name]))\n",
    "  one_hot = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)\n",
    "\n",
    "\n",
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "pitch_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model = pitch_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_features_dict = {name: np.array(value) \n",
    "                         for name, value in pitch_features.items()}\n",
    "\n",
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "\n",
    "\n",
    "def gen_pitch_model(preprocessing_head, inputs):\n",
    "  body = tf.keras.Sequential([\n",
    "    layers.Dense(64),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  preprocessed_inputs = preprocessing_head(inputs)\n",
    "  result = body(preprocessed_inputs)\n",
    "  model = tf.keras.Model(inputs, result)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
    "  return model\n",
    "\n",
    "pitch_model = gen_pitch_model(pitch_preprocessing, inputs)\n",
    "\n",
    "pitch_model.fit(x=titanic_features_dict, y=pitch_labels, epochs=50)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
