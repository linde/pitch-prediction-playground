{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q numpy pandas tensorflow\n",
    "\n",
    "## references\n",
    "# https://keras.io/examples/structured_data/structured_data_classification_from_scratch/\n",
    "# https://www.kaggle.com/datasets/pschale/mlb-pitch-data-20152018/code\n",
    "# https://www.kaggle.com/code/ryancmcv/mlb-pitch-data\n",
    "# https://stackoverflow.com/questions/64689483/how-to-do-multiclass-classification-with-keras\n",
    "\n",
    "# to_ordinal https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_ordinal\n",
    "# to_categorical https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##!curl -s 'https://storage.googleapis.com/0x19f.com/media/kaggle-mlb-pitch-data-2015-2018.tgz' | tar xz\n",
    "\n",
    "BASEBALL_FILES_BASE = os.getcwd() + \"/kaggle-mlb-pitch-data-2015-2018/\"\n",
    "BASEBALL_FILES_BASE = BASEBALL_FILES_BASE + \"2019_\"  # just look at 2019 to speed things up\n",
    "\n",
    "\n",
    "pitches = pd.read_csv(BASEBALL_FILES_BASE + 'pitches.csv')\n",
    "atbats = pd.read_csv(BASEBALL_FILES_BASE + 'atbats.csv')\n",
    "\n",
    "df = pd.merge(pitches, atbats, how='inner', on='ab_id')\n",
    "\n",
    "df = df[[\n",
    "    # situation stuff\n",
    "    \"ab_id\", \"inning\", \"top\", \"outs\", \"on_1b\", \"on_2b\", \"on_3b\",\n",
    "\n",
    "    # matchup\n",
    "    \"pitcher_id\", \"p_throws\", \"batter_id\", \"stand\",\n",
    "\n",
    "    # specific pitch state\n",
    "    \"pitch_num\", \"b_count\", \"s_count\",\n",
    "    # TODO need to add running total of pitches for the current pitcher, and maybe strike percentage\n",
    "    # TODO add the previous n pitches before and their code outcome\n",
    "    # \n",
    "    \n",
    "    # this is the label we're trying to predict\n",
    "    \"code\",\n",
    "    \"pitch_type\",\n",
    "    # TODO also make the label have the location. not just FF (fourseam fastball, but also high inside)\n",
    "]]\n",
    "\n",
    "# remove anything without a pitchtype (add more as helpful)\n",
    "df = df.dropna(subset=['pitch_type', 'code'])\n",
    "\n",
    "# make our target label\n",
    "# for now, whether the pritcher threw a hitable pitch, that is having codes:\n",
    "# S - Swinging Strike\n",
    "# C - Called Strike\n",
    "# F - Foul\n",
    "# T - Foul Tip\n",
    "# L - Foul Bunt\n",
    "\n",
    "hittablePitchCodes = [\"S\", \"C\", \"F\", \"T\", \"L\", ]\n",
    "df['target_label'] = np.where(df['code'].isin(hittablePitchCodes), 1, 0)\n",
    "\n",
    "\n",
    "# simple number codes for strings\n",
    "df['p_throws_right'] = np.where(df['p_throws'].isin(['R']), 1, 0)\n",
    "df['b_stands_right'] = np.where(df['stand'].isin(['R']), 1, 0)\n",
    "\n",
    "# get appropriate types. \n",
    "# TODO prob can use a schema on the CSV read to get only the columns we're after, alias them to be more\n",
    "#      useful, and cast to the right type\n",
    "# TODO consider to_ordinal for cumulative things maybe? inning, outs, pitch_num, b_count, s_count\n",
    "df = df.astype({\n",
    "    'ab_id': 'int32',\n",
    "    'inning': 'int8',\n",
    "    'top': 'int8',\n",
    "    'outs': 'int8',\n",
    "    'on_1b': 'int8',\n",
    "    'on_2b': 'int8',\n",
    "    'on_3b': 'int8',\n",
    "    'pitch_num': 'int8',\n",
    "    'b_count': 'int8',\n",
    "    's_count': 'int8',\n",
    "  })\n",
    "\n",
    "# drop ab_id now that join has occured and others we've encoded\n",
    "df = df.drop(['ab_id', 'code', 'pitch_type', 'p_throws', 'stand', ], axis=1)\n",
    "\n",
    "df = df.truncate(after=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target_label\"].value_counts()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "val_dataframe = df.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = df.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")\n",
    "\n",
    "\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target_label\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "\n",
    "print(train_ds.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup_class is one of StringLookup, IntegerLookup\n",
    "def encode_categorical_feature(feature, name, dataset, lookup_class):\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode=\"int\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "encodedFields = []\n",
    "all_inputs = []\n",
    "\n",
    "string_fields = [\"pitch_type\", \"pitch_type\"]\n",
    "\n",
    "for f in [\n",
    "    'pitcher_id', 'batter_id', 'top', 'on_1b', 'on_2b', 'on_3b', \n",
    "    'b_count','s_count', 'p_throws_right', 'b_stands_right', 'inning', 'outs', 'pitch_num',\n",
    "]:\n",
    "    print(\"encoding %s ...\" % f)\n",
    "    input = keras.Input(shape=(1,), name=f)\n",
    "    all_inputs.append(input)\n",
    "\n",
    "    feature_ds = train_ds.map(lambda x, y: x[f])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    lookup_class = StringLookup if (f in string_fields) else IntegerLookup\n",
    "    lookup = lookup_class(output_mode=\"int\")\n",
    "    lookup.adapt(feature_ds)\n",
    "    encoded_feature = lookup(input)    \n",
    "    encodedFields.append(encoded_feature)\n",
    "\n",
    "\n",
    "## TODO also encode the pitch_type which is in the is this right? \n",
    "\n",
    "# label_field = \"pitch_type\"\n",
    "# print(\"encoding label %s ...\" % label_field)\n",
    "# label_input = keras.Input(shape=(1,), name=label_field) # TODO should this be an \"keras.Output\"?\n",
    "# label_input_encoded = encode_categorical_feature(input, label_field, val_ds, IntegerLookup)\n",
    "# encodedFields.append(label_input_encoded)\n",
    "    \n",
    "\n",
    "all_features = layers.concatenate(encodedFields)\n",
    "\n",
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(all_inputs, output)\n",
    "\n",
    "# TODO categorical_crossentropy or binary_crossentropy?\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(train_ds, epochs=10, validation_data=val_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
