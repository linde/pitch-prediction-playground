{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install -q numpy pandas tensorflow\n",
    "\n",
    "## references\n",
    "# https://keras.io/examples/structured_data/structured_data_classification_from_scratch/\n",
    "# https://www.kaggle.com/datasets/pschale/mlb-pitch-data-20152018/code\n",
    "# https://www.kaggle.com/code/ryancmcv/mlb-pitch-data\n",
    "# https://stackoverflow.com/questions/64689483/how-to-do-multiclass-classification-with-keras\n",
    "\n",
    "# to_ordinal https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_ordinal\n",
    "# to_categorical https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##!curl -s 'https://storage.googleapis.com/0x19f.com/media/kaggle-mlb-pitch-data-2015-2018.tgz' | tar xz\n",
    "\n",
    "BASEBALL_FILES_BASE = os.getcwd() + \"/kaggle-mlb-pitch-data-2015-2018/\"\n",
    "BASEBALL_FILES_BASE = BASEBALL_FILES_BASE + \"2019_\"  # just look at 2019 to speed things up\n",
    "\n",
    "\n",
    "pitches = pd.read_csv(BASEBALL_FILES_BASE + 'pitches.csv')\n",
    "atbats = pd.read_csv(BASEBALL_FILES_BASE + 'atbats.csv')\n",
    "\n",
    "df = pd.merge(pitches, atbats, how='inner', on='ab_id')\n",
    "\n",
    "df = df[[\n",
    "    # situation stuff\n",
    "    \"ab_id\", \"inning\", \"top\", \"outs\", \"on_1b\", \"on_2b\", \"on_3b\",\n",
    "\n",
    "    # matchup\n",
    "    \"pitcher_id\", \"p_throws\", \"batter_id\", \"stand\",\n",
    "\n",
    "    # specific pitch state\n",
    "    \"pitch_num\", \"b_count\", \"s_count\",\n",
    "    # TODO need to add running total of pitches for the current pitcher, and maybe strike percentage\n",
    "    # TODO add the previous n pitches before and their code outcome\n",
    "    # \n",
    "    \n",
    "    # this is the label we're trying to predict\n",
    "    \"code\",\n",
    "    \"pitch_type\",\n",
    "    # TODO also make the label have the location. not just FF (fourseam fastball, but also high inside)\n",
    "]]\n",
    "\n",
    "# remove anything without a pitchtype (add more as helpful)\n",
    "df = df.dropna(subset=['pitch_type', 'code'])\n",
    "\n",
    "# make our target label\n",
    "# for now, whether the pritcher threw a hitable pitch, that is having codes:\n",
    "# S - Swinging Strike\n",
    "# C - Called Strike\n",
    "# F - Foul\n",
    "# T - Foul Tip\n",
    "# L - Foul Bunt\n",
    "\n",
    "hittablePitchCodes = [\"S\", \"C\", \"F\", \"T\", \"L\", ]\n",
    "df['target_label'] = np.where(df['code'].isin(hittablePitchCodes), 1, 0)\n",
    "\n",
    "\n",
    "# simple number codes for strings\n",
    "df['p_throws_right'] = np.where(df['p_throws'].isin(['R']), 1, 0)\n",
    "df['b_stands_right'] = np.where(df['stand'].isin(['R']), 1, 0)\n",
    "\n",
    "# get appropriate types. \n",
    "# TODO prob can use a schema on the CSV read to get only the columns we're after, alias them to be more\n",
    "#      useful, and cast to the right type\n",
    "# TODO consider to_ordinal for cumulative things maybe? inning, outs, pitch_num, b_count, s_count\n",
    "df = df.astype({\n",
    "    'ab_id': 'int32',\n",
    "    'inning': 'int8',\n",
    "    'top': 'int8',\n",
    "    'outs': 'int8',\n",
    "    'on_1b': 'int8',\n",
    "    'on_2b': 'int8',\n",
    "    'on_3b': 'int8',\n",
    "    'pitch_num': 'int8',\n",
    "    'b_count': 'int8',\n",
    "    's_count': 'int8',\n",
    "  })\n",
    "\n",
    "# drop ab_id now that join has occured and others we've encoded\n",
    "df = df.drop(['ab_id', 'code', 'pitch_type', 'p_throws', 'stand', ], axis=1)\n",
    "\n",
    "df = df.truncate(after=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pitch_type\n",
       "FF    3702\n",
       "SL    1732\n",
       "CH    1139\n",
       "SI     841\n",
       "CU     820\n",
       "FT     673\n",
       "FC     630\n",
       "KC     302\n",
       "FS     129\n",
       "EP       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"pitch_type\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 7977 samples for training and 1994 for validation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "val_dataframe = df.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = df.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")\n",
    "\n",
    "\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"pitch_type\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding pitcher_id ...\n",
      "encoding batter_id ...\n",
      "encoding top ...\n",
      "encoding on_1b ...\n",
      "encoding on_2b ...\n",
      "encoding on_3b ...\n",
      "encoding b_count ...\n",
      "encoding s_count ...\n",
      "encoding p_throws_right ...\n",
      "encoding b_stands_right ...\n",
      "encoding inning ...\n",
      "encoding outs ...\n",
      "encoding pitch_num ...\n"
     ]
    }
   ],
   "source": [
    "# lookup_class is one of StringLookup, IntegerLookup\n",
    "def encode_categorical_feature(feature, name, dataset, lookup_class):\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode=\"int\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "encodedFields = []\n",
    "all_inputs = []\n",
    "\n",
    "string_fields = [\"pitch_type\", \"pitch_type\"]\n",
    "\n",
    "for f in [\n",
    "    'pitcher_id', 'batter_id', 'top', 'on_1b', 'on_2b', 'on_3b', \n",
    "    'b_count','s_count', 'p_throws_right', 'b_stands_right', 'inning', 'outs', 'pitch_num',\n",
    "]:\n",
    "    print(\"encoding %s ...\" % f)\n",
    "    input = keras.Input(shape=(1,), name=f)\n",
    "    all_inputs.append(input)\n",
    "\n",
    "    feature_ds = train_ds.map(lambda x, y: x[f])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    lookup_class = StringLookup if (f in string_fields) else IntegerLookup\n",
    "    lookup = lookup_class(output_mode=\"int\")\n",
    "    lookup.adapt(feature_ds)\n",
    "    encoded_feature = lookup(input)    \n",
    "    encodedFields.append(encoded_feature)\n",
    "\n",
    "\n",
    "## TODO also encode the pitch_type which is in the is this right? \n",
    "\n",
    "# label_field = \"pitch_type\"\n",
    "# print(\"encoding label %s ...\" % label_field)\n",
    "# label_input = keras.Input(shape=(1,), name=label_field) # TODO should this be an \"keras.Output\"?\n",
    "# label_input_encoded = encode_categorical_feature(input, label_field, val_ds, IntegerLookup)\n",
    "# encodedFields.append(label_input_encoded)\n",
    "    \n",
    "\n",
    "all_features = layers.concatenate(encodedFields)\n",
    "\n",
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(all_inputs, output)\n",
    "\n",
    "# TODO categorical_crossentropy or binary_crossentropy?\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 15:41:18.290617: W tensorflow/core/framework/op_kernel.cc:1805] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'binary_crossentropy/Cast' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3163/581066605.py\", line 1, in <module>\n      model.fit(train_ds, epochs=10, validation_data=val_ds)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/losses.py\", line 2421, in binary_crossentropy\n      y_true = tf.cast(y_true, y_pred.dtype)\nNode: 'binary_crossentropy/Cast'\nCast string to float is not supported\n\t [[{{node binary_crossentropy/Cast}}]] [Op:__inference_train_function_127327]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_ds, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mval_ds)\n",
      "File \u001b[0;32m~/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'binary_crossentropy/Cast' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3163/581066605.py\", line 1, in <module>\n      model.fit(train_ds, epochs=10, validation_data=val_ds)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/stevenlinde/src/etc/aiml-inference-playground/.venv/lib/python3.9/site-packages/keras/src/losses.py\", line 2421, in binary_crossentropy\n      y_true = tf.cast(y_true, y_pred.dtype)\nNode: 'binary_crossentropy/Cast'\nCast string to float is not supported\n\t [[{{node binary_crossentropy/Cast}}]] [Op:__inference_train_function_127327]"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(train_ds, epochs=10, validation_data=val_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
