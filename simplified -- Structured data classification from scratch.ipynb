{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 08:25:47.036108: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-22 08:25:47.082330: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-22 08:25:47.083228: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-22 08:25:47.861648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install -q numpy pandas tensorflow\n",
    "\n",
    "## references\n",
    "# https://keras.io/examples/structured_data/structured_data_classification_from_scratch/\n",
    "# https://www.kaggle.com/datasets/pschale/mlb-pitch-data-20152018/code\n",
    "# https://www.kaggle.com/code/ryancmcv/mlb-pitch-data\n",
    "# https://stackoverflow.com/questions/64689483/how-to-do-multiclass-classification-with-keras\n",
    "\n",
    "# to_ordinal https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_ordinal\n",
    "# to_categorical https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical\n",
    "\n",
    "# TODO filter features that fewer than n instances (ie pitchers who only pitched a game or so.) n=5 maybe?\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 242 samples for training and 61 for validation\n"
     ]
    }
   ],
   "source": [
    "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "val_dataframe = df.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = df.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'age': <tf.Tensor: shape=(), dtype=int64, numpy=54>, 'sex': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'cp': <tf.Tensor: shape=(), dtype=int64, numpy=4>, 'trestbps': <tf.Tensor: shape=(), dtype=int64, numpy=120>, 'chol': <tf.Tensor: shape=(), dtype=int64, numpy=188>, 'fbs': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'restecg': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'thalach': <tf.Tensor: shape=(), dtype=int64, numpy=113>, 'exang': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'oldpeak': <tf.Tensor: shape=(), dtype=float64, numpy=1.4>, 'slope': <tf.Tensor: shape=(), dtype=int64, numpy=2>, 'ca': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'thal': <tf.Tensor: shape=(), dtype=string, numpy=b'reversible'>}\n",
      "Target: tf.Tensor(1, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    copied_dataframe = dataframe.copy()\n",
    "    labels = copied_dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(copied_dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(copied_dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)\n",
    "\n",
    "\n",
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'age': <tf.Tensor: shape=(), dtype=int64, numpy=61>, 'sex': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'cp': <tf.Tensor: shape=(), dtype=int64, numpy=4>, 'trestbps': <tf.Tensor: shape=(), dtype=int64, numpy=140>, 'chol': <tf.Tensor: shape=(), dtype=int64, numpy=207>, 'fbs': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'restecg': <tf.Tensor: shape=(), dtype=int64, numpy=2>, 'thalach': <tf.Tensor: shape=(), dtype=int64, numpy=138>, 'exang': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'oldpeak': <tf.Tensor: shape=(), dtype=float64, numpy=1.9>, 'slope': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'ca': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'thal': <tf.Tensor: shape=(), dtype=string, numpy=b'reversible'>}\n",
      "Target: tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)\n",
    "\n",
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)\n",
    "\n",
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_categorical_feature(feature, name, dataset, is_string):\n",
    "    lookup_class = StringLookup if is_string else IntegerLookup\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_feature_layers, all_inputs = [], []\n",
    "\n",
    "for feature_name in [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"ca\",]:\n",
    "    feature_input = keras.Input(shape=(1,), name=feature_name, dtype=\"int64\")\n",
    "    all_inputs.append(feature_input)\n",
    "    feature_encoded = encode_categorical_feature(feature_input, feature_name, train_ds, False)\n",
    "    all_feature_layers.append(feature_encoded)\n",
    "\n",
    "string_categorial_features = [\"thal\"]\n",
    "for feature_name in string_categorial_features:\n",
    "    feature_input = keras.Input(shape=(1,), name=feature_name, dtype=\"string\")\n",
    "    all_inputs.append(feature_input)\n",
    "    feature_encoded = encode_categorical_feature(feature_input, feature_name, train_ds, True)\n",
    "    all_feature_layers.append(feature_encoded)\n",
    "\n",
    "numeric_categorial_features = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\", \"slope\", ]\n",
    "for feature_name in numeric_categorial_features:\n",
    "    feature_input = keras.Input(shape=(1,), name=feature_name, dtype=\"float32\")\n",
    "    all_inputs.append(feature_input)\n",
    "    feature_encoded = encode_numerical_feature(feature_input, feature_name, train_ds)\n",
    "    all_feature_layers.append(feature_encoded)\n",
    "\n",
    "\n",
    "all_features = layers.concatenate(all_feature_layers)\n",
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 0.8019 - accuracy: 0.4711 - val_loss: 0.7103 - val_accuracy: 0.5082\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7475 - accuracy: 0.5000 - val_loss: 0.6359 - val_accuracy: 0.6230\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6590 - accuracy: 0.6281 - val_loss: 0.5810 - val_accuracy: 0.7049\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6313 - accuracy: 0.6240 - val_loss: 0.5378 - val_accuracy: 0.7541\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5688 - accuracy: 0.6612 - val_loss: 0.5053 - val_accuracy: 0.7541\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5774 - accuracy: 0.6901 - val_loss: 0.4795 - val_accuracy: 0.7869\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5256 - accuracy: 0.7438 - val_loss: 0.4595 - val_accuracy: 0.8197\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5216 - accuracy: 0.7521 - val_loss: 0.4437 - val_accuracy: 0.8197\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4567 - accuracy: 0.8017 - val_loss: 0.4308 - val_accuracy: 0.8197\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4563 - accuracy: 0.7810 - val_loss: 0.4207 - val_accuracy: 0.8197\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4579 - accuracy: 0.7975 - val_loss: 0.4128 - val_accuracy: 0.8197\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4409 - accuracy: 0.7934 - val_loss: 0.4056 - val_accuracy: 0.8197\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4562 - accuracy: 0.7769 - val_loss: 0.3997 - val_accuracy: 0.8197\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4266 - accuracy: 0.7975 - val_loss: 0.3952 - val_accuracy: 0.8197\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8388 - val_loss: 0.3912 - val_accuracy: 0.8361\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8264 - val_loss: 0.3882 - val_accuracy: 0.8361\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4263 - accuracy: 0.8182 - val_loss: 0.3848 - val_accuracy: 0.8525\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3894 - accuracy: 0.8347 - val_loss: 0.3818 - val_accuracy: 0.8525\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3627 - accuracy: 0.8554 - val_loss: 0.3799 - val_accuracy: 0.8525\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3579 - accuracy: 0.8430 - val_loss: 0.3788 - val_accuracy: 0.8525\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3800 - accuracy: 0.8058 - val_loss: 0.3774 - val_accuracy: 0.8525\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3615 - accuracy: 0.8471 - val_loss: 0.3765 - val_accuracy: 0.8525\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3962 - accuracy: 0.8264 - val_loss: 0.3766 - val_accuracy: 0.8689\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3475 - accuracy: 0.8471 - val_loss: 0.3755 - val_accuracy: 0.8689\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3489 - accuracy: 0.8512 - val_loss: 0.3745 - val_accuracy: 0.8689\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3371 - accuracy: 0.8554 - val_loss: 0.3740 - val_accuracy: 0.8689\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3429 - accuracy: 0.8347 - val_loss: 0.3731 - val_accuracy: 0.8689\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3239 - accuracy: 0.8636 - val_loss: 0.3725 - val_accuracy: 0.8689\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3458 - accuracy: 0.8182 - val_loss: 0.3725 - val_accuracy: 0.8689\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3534 - accuracy: 0.8678 - val_loss: 0.3718 - val_accuracy: 0.8689\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3178 - accuracy: 0.8512 - val_loss: 0.3716 - val_accuracy: 0.8689\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3311 - accuracy: 0.8430 - val_loss: 0.3723 - val_accuracy: 0.8689\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3077 - accuracy: 0.8636 - val_loss: 0.3724 - val_accuracy: 0.8689\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3346 - accuracy: 0.8264 - val_loss: 0.3722 - val_accuracy: 0.8689\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3077 - accuracy: 0.8678 - val_loss: 0.3716 - val_accuracy: 0.8689\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3083 - accuracy: 0.8554 - val_loss: 0.3719 - val_accuracy: 0.8689\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3305 - accuracy: 0.8347 - val_loss: 0.3720 - val_accuracy: 0.8689\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3035 - accuracy: 0.8802 - val_loss: 0.3725 - val_accuracy: 0.8525\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2660 - accuracy: 0.8843 - val_loss: 0.3729 - val_accuracy: 0.8525\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3019 - accuracy: 0.8595 - val_loss: 0.3732 - val_accuracy: 0.8525\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2876 - accuracy: 0.8595 - val_loss: 0.3733 - val_accuracy: 0.8525\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3206 - accuracy: 0.8388 - val_loss: 0.3742 - val_accuracy: 0.8689\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2937 - accuracy: 0.8678 - val_loss: 0.3750 - val_accuracy: 0.8689\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2798 - accuracy: 0.8636 - val_loss: 0.3742 - val_accuracy: 0.8689\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2957 - accuracy: 0.8719 - val_loss: 0.3740 - val_accuracy: 0.8525\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2906 - accuracy: 0.8512 - val_loss: 0.3731 - val_accuracy: 0.8361\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2901 - accuracy: 0.8636 - val_loss: 0.3728 - val_accuracy: 0.8361\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2975 - accuracy: 0.8760 - val_loss: 0.3719 - val_accuracy: 0.8361\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.8843 - val_loss: 0.3719 - val_accuracy: 0.8361\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2860 - accuracy: 0.8802 - val_loss: 0.3719 - val_accuracy: 0.8361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7e65b25cbd60>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=50, validation_data=val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 169ms/step\n",
      "This particular patient had a 41.1 percent probability of having a heart disease, as evaluated by our model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.41055062]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = {\n",
    "    \"age\": 55,\n",
    "    \"sex\": 1,\n",
    "    \"cp\": 1,\n",
    "    \"trestbps\": 145,\n",
    "    \"chol\": 210,\n",
    "    \"fbs\": 1,\n",
    "    \"restecg\": 2,\n",
    "    \"thalach\": 150,\n",
    "    \"exang\": 0,\n",
    "    \"oldpeak\": 2.3,\n",
    "    \"slope\": 3,\n",
    "    \"ca\": 0,\n",
    "    \"thal\": \"fixed\",\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = model.predict(input_dict)\n",
    "\n",
    "print(\n",
    "    \"This particular patient had a %.1f percent probability \"\n",
    "    \"of having a heart disease, as evaluated by our model.\" % (100 * predictions[0][0],)\n",
    ")\n",
    "\n",
    "predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
