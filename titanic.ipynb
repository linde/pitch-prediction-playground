{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-04 19:14:22.177803: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-04 19:14:22.206153: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-04 19:14:22.207092: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-04 19:14:22.833672: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.losses import BinaryCrossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 627 entries, 0 to 626\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   survived            627 non-null    int8  \n",
      " 1   sex                 627 non-null    object\n",
      " 2   age                 627 non-null    int8  \n",
      " 3   n_siblings_spouses  627 non-null    int8  \n",
      " 4   parch               627 non-null    int8  \n",
      " 5   fare                627 non-null    int16 \n",
      " 6   class               627 non-null    object\n",
      " 7   deck                627 non-null    object\n",
      " 8   embark_town         627 non-null    object\n",
      " 9   alone               627 non-null    object\n",
      "dtypes: int16(1), int8(4), object(5)\n",
      "memory usage: 28.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the Titanic dataset.\n",
    "titanic_df = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic = titanic_df.astype({\n",
    "    'survived': 'int8',\n",
    "    'age': 'int8',\n",
    "    'n_siblings_spouses': 'int8',\n",
    "    'parch': 'int8',\n",
    "    'fare': 'int16',\n",
    "})\n",
    "\n",
    "titanic.info()\n",
    "\n",
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# attempts to (eventually) preprocess a dataframe of features\n",
    "# returns all of the collected inputs and preprocessed features \n",
    "def process_dataframe_inputs(feature_df):\n",
    "\n",
    "  # first we walk through each feature in the dataframe, make an input for it,\n",
    "  # normalize it using the feature_df data, then collect it into lists of\n",
    "  # inputs and preprocessed inputs, respectively\n",
    "\n",
    "  input_layers, preprocessed_inputs  = [], []\n",
    "  for name, col in feature_df.items():\n",
    "\n",
    "    # TODO do this with log() ... print(\"processing %s ...\" % name)\n",
    "\n",
    "    # convert to tensorflow types. this is straightforward except \n",
    "    # for objects, treat them as strings.\n",
    "    dtype_str = str(col.dtype) if col.dtype != object else \"string\"\n",
    "    cur_dtype = tf.as_dtype(dtype_str)\n",
    "    cur_input = tf.keras.Input(shape=(1,), name=name, dtype=cur_dtype)\n",
    "    input_layers.append(cur_input)  \n",
    "\n",
    "    if cur_dtype == tf.string:\n",
    "      lookup = layers.StringLookup(vocabulary=np.unique(col))    \n",
    "      norm = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "      normalized_input = norm(lookup(cur_input))\n",
    "      preprocessed_inputs.append(normalized_input)\n",
    "\n",
    "    else:\n",
    "      norm = layers.Normalization(axis=None)\n",
    "      norm.adapt(col)\n",
    "      normalized_input = norm(cur_input)\n",
    "      preprocessed_inputs.append( normalized_input )\n",
    "\n",
    "  # prepare the return values by concatentating the preprocessed inputs\n",
    "  # and creating a model for which they serve as outputs.\n",
    "  # \n",
    "  # returns the input layers and the processed_inputs, respectively\n",
    "\n",
    "  preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "  preprocessing_model = tf.keras.Model(input_layers, preprocessed_inputs_cat)\n",
    "  preprocessed_inputs = preprocessing_model(input_layers)\n",
    "\n",
    "  return input_layers, preprocessed_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-04 19:14:44.968521: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 1s 3ms/step - loss: 5.9552 - accuracy: 0.4242\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8530 - accuracy: 0.4737\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.5888 - accuracy: 0.5295\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.1668 - accuracy: 0.5407\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.1112 - accuracy: 0.5726\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 5.1041 - accuracy: 0.5439\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 4.8088 - accuracy: 0.5742\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 4.3630 - accuracy: 0.5694\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.6002 - accuracy: 0.5662\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 2.8844 - accuracy: 0.6124\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.4414 - accuracy: 0.6396\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.2638 - accuracy: 0.6603\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.8866 - accuracy: 0.6746\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.4060 - accuracy: 0.6715\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.9263 - accuracy: 0.6539\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.9029 - accuracy: 0.7177\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.7592\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.7624\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.7656\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7815\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7671\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7783\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.7735\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7815\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.7799\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7879\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.7416\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7703\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7959\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7783\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.7560\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.3709 - accuracy: 0.6746\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.2504 - accuracy: 0.7113\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.0934 - accuracy: 0.7273\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.8021 - accuracy: 0.7592\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.7592\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.7719\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.7703\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.7703\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.7687\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7475 - accuracy: 0.7703\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7671\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7911\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.7895\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7608\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7496\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7815\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7624\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7767\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7863\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7863\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7767\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7767\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7911\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7943\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7943\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7735\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.7959\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7990\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7943\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7879\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7879\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8006\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7911\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7927\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.7305\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.6842\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.7145\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7815\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7895\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.8054\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7911\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7783\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7847\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8038\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.8086\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7895\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.8006\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7831\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7927\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.8054\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7911\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7959\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7911\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8022\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7911\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8054\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7990\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7927\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7990\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7990\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7847\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7959\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7959\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7895\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7847\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8038\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7990\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7815\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7911\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_layers, preprocessed_inputs = process_dataframe_inputs(titanic_features)\n",
    "\n",
    "seqential_hidden_model = tf.keras.Sequential([\n",
    "  layers.Dropout(0.10),\n",
    "  layers.Dense(16),\n",
    "  layers.Dense(16),\n",
    "  layers.Dense(8),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "result = seqential_hidden_model(preprocessed_inputs)\n",
    "titanic_model = tf.keras.Model(input_layers, result)\n",
    "titanic_model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "titanic_features_dict = {\n",
    "  name: np.array(value) for name, value in titanic_features.items()\n",
    "}\n",
    "\n",
    "hist = titanic_model.fit(x=titanic_features_dict, y=titanic_labels, epochs=100, batch_size=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(hist.epoch, hist.history['loss'], label='loss', color=\"blue\")\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(hist.epoch, hist.history['accuracy'], label='accuracy', color=\"red\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# tf.keras.utils.plot_model(model = titanic_model, rankdir=\"LR\",)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
