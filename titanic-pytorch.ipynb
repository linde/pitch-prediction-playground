{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2105a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from modules.classifer_utils import ClassifierDataset, TrainingManager\n",
    "\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8680d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset.\n",
    "titanic_train_csv_df = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic_test_csv_df = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\")\n",
    "\n",
    "print(f'titanic_train_csv_df shape: {titanic_train_csv_df.shape}')\n",
    "print(f'titanic_test_csv_df shape: {titanic_test_csv_df.shape}')\n",
    "\n",
    "# concat test and train to get metadata for non numeric categories\n",
    "csv_union_df = pd.concat([titanic_test_csv_df, titanic_train_csv_df])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3770164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_column_name = \"survived\"\n",
    "[train_encoded_df, test_encoded_df] = ClassifierDataset.onehot_encode_datafames([titanic_train_csv_df, titanic_test_csv_df])\n",
    "\n",
    "\n",
    "train_ds = ClassifierDataset(train_encoded_df, label_column_name)\n",
    "test_ds = ClassifierDataset(test_encoded_df, label_column_name)\n",
    "\n",
    "batch_size = int(len(train_ds) / 10)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_ds, shuffle=True)\n",
    "print(f'{len(train_ds)} training records in with batch size {batch_size}, {len(test_ds)} records for test')\n",
    "\n",
    "print(f'train has {train_ds.get_feature_count()} features')\n",
    "print(f'test has {test_ds.get_feature_count()} features')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f7a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT_RATE_01 = .20\n",
    "\n",
    "# TODO have a config for layers and wire them from it\n",
    "\n",
    "class TitanicSurvivalNeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_feature_columns):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(num_feature_columns, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=DROPOUT_RATE_01), \n",
    "            nn.Linear(64, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=DROPOUT_RATE_01), \n",
    "            nn.Linear(64, 32),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=DROPOUT_RATE_01), \n",
    "            nn.Linear(32, 32),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "\n",
    "\n",
    "first_training_record, _ = train_ds[0]\n",
    "num_features = first_training_record.shape[-1]\n",
    "model = TitanicSurvivalNeuralNetwork( num_features)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f73cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_training_record, _ = train_ds[0]\n",
    "num_feature_columns = first_training_record.shape[-1]\n",
    "model = TitanicSurvivalNeuralNetwork( num_feature_columns )\n",
    "\n",
    "training_mgr = TrainingManager(model)\n",
    "training_mgr.train(train_dataloader, 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb671ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_mgr.eval(test_dataloader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
