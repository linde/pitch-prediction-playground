{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2391c20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "\n",
    "from modules.classifer_utils import NormalizedClassifierDataset, NormalizedClassifierDatasetMetadata, TrainingManager, GeneralNN\n",
    "\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14c5eb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with 279660 records on disk\n",
      "target label breakdown\n",
      "is_fastball\n",
      "0    156297\n",
      "1    121669\n",
      "Name: count, dtype: int64\n",
      "201266 batches with batch_size: 20126, 50316 batches for test.\n",
      "datasets have 29 features\n"
     ]
    }
   ],
   "source": [
    "games_df = pd.read_parquet(\"games/statcast-2020.parquet\")\n",
    "print(f'starting with {len(games_df)} records on disk')\n",
    "\n",
    "\n",
    "## some cleanup stuff\n",
    "\n",
    "# first off, ditch rows without our target label\n",
    "rows_to_drop = games_df[games_df.pitch_type.isna()].index\n",
    "games_df.drop(rows_to_drop, inplace=True)\n",
    "\n",
    "# for now, let's make this a binary classifier. we can later try to predict specific pitches\n",
    "LABEL_COLUMN_NAME = \"is_fastball\"\n",
    "games_df[LABEL_COLUMN_NAME] = games_df.pitch_type.str.startswith('F').astype(int)\n",
    "print(f'target label breakdown\\n{games_df[LABEL_COLUMN_NAME].value_counts()}')\n",
    "\n",
    "# turn player ids on base into flags (dont want to bother embedding, too sparse)\n",
    "for col in [\"on_1b\", \"on_2b\", \"on_3b\"]:\n",
    "    games_df[col + \"_notna\"] = games_df[col].notna().astype(int)\n",
    "    games_df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# TODO figure out date as a categorical\n",
    "DAY_OF_YEAR = 'day_of_year'\n",
    "games_df[DAY_OF_YEAR] = games_df.game_date.dt.dayofyear\n",
    "\n",
    "# cast some types\n",
    "games_df = games_df.astype({\n",
    "    'pitcher': 'int', \n",
    "    'batter': 'int',\n",
    "}, errors='ignore')\n",
    "\n",
    "\n",
    "# ok, ready to set up our dataset\n",
    "\n",
    "ds_meta = NormalizedClassifierDatasetMetadata(LABEL_COLUMN_NAME)\n",
    "ds_meta.set_ordinal_numeric_cols( [\n",
    "    \"bat_score\", \n",
    "    \"fld_score\", \n",
    "    \"balls\", \n",
    "    \"strikes\", \n",
    "    \"outs_when_up\",   \n",
    "    DAY_OF_YEAR,\n",
    "    \"at_bat_number\",\n",
    "    \"pitch_number\",\n",
    "    \"n_thruorder_pitcher\",\n",
    "    \"age_pit\",\n",
    "    \"age_bat\",\n",
    "    \"pitcher_days_since_prev_game\"\n",
    "] )\n",
    "\n",
    "ds_meta.set_categorical_map({\n",
    "    col : list(games_df[col].unique()) for col in ['p_throws', 'stand']  #, 'if_fielding_alignment', 'of_fielding_alignment']\n",
    "})\n",
    "\n",
    "ds_meta.set_embedding_cols([\"pitcher\", \"batter\"])\n",
    "\n",
    "target_df = games_df[ ds_meta.get_columns() ].dropna()\n",
    "\n",
    "\n",
    "overall_ds = NormalizedClassifierDataset(target_df, ds_meta)\n",
    "\n",
    "\n",
    "train_ds, test_ds = random_split(overall_ds, [.80, .20])\n",
    "\n",
    "batch_size = int(len(train_ds) / 10)\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "print(f'{len(train_ds)} batches with batch_size: {batch_size}, {len(test_ds)} batches for test.')\n",
    "num_features = overall_ds.get_feature_count()\n",
    "print(f'datasets have {num_features} features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e65d4965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 8651 parameters.\n",
      "trainging using: cpu device\n",
      "Epoch [1/100], Avg training Loss: 51.4083, Accuracy: 96261/201260 (0.4783)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m parameters.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m training_mgr = TrainingManager(model)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtraining_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:14\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(self, dataloader, num_epochs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/github.com/linde/pitch-prediction-playground/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/github.com/linde/pitch-prediction-playground/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/github.com/linde/pitch-prediction-playground/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/github.com/linde/pitch-prediction-playground/.venv/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/github.com/linde/pitch-prediction-playground/.venv/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/github.com/linde/pitch-prediction-playground/modules/classifer_utils.py:119\u001b[39m, in \u001b[36mNormalizedClassifierDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m    118\u001b[39m     features_tensor = torch.tensor(\u001b[38;5;28mself\u001b[39m.features_ndarray[idx], dtype=torch.float32)\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     label_tensor = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabels_ndarray\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m features_tensor, label_tensor\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "dropoutRate = 0.2\n",
    "\n",
    "input_features = overall_ds.get_feature_count()\n",
    "model = GeneralNN( input_features, [num_features*2,num_features*2,32,32,16,1], dropoutRate )\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"The model has {total_params} parameters.\")\n",
    "\n",
    "training_mgr = TrainingManager(model)\n",
    "training_mgr.train(train_dataloader, 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7093ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs  = 10\n",
    "\n",
    "print(f'normed_df has {len(normed_df)} records')\n",
    "\n",
    "\n",
    "overall_ds = NormalizedClassifierDataset(normed_df, ds_meta)\n",
    "\n",
    "print(f'overall_ds has {len(overall_ds)} records')\n",
    "\n",
    "train_ds, test_ds = random_split(overall_ds, [.80, .20])\n",
    "\n",
    "batch_size = int(len(train_ds) / 10)\n",
    "dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "# print(f'overall_ds len {len(overall_ds)} over {len(normed_df)} records')\n",
    "# for epoch_idx, epoch in enumerate(range(num_epochs)):\n",
    "\n",
    "#     epoch_records = 0\n",
    "#     for X, y in dataloader:\n",
    "#         batch_records = len(X)\n",
    "#         epoch_records += batch_records\n",
    "#         print(f'processing in dataloader loop {batch_records} records, {epoch_records} so far')\n",
    "        \n",
    "#     print(f'epoch {epoch_idx} of {num_epochs} over: {epoch_records} overall')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91977d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mgr.eval(test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
