{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2391c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from modules.classifer_utils import NormalizedClassifierDataset, NormalizedClassifierDatasetMetadata, TrainingManager, GeneralNN\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c5eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs = [ pd.read_parquet(f\"games/statcast-{y}.parquet\") for y in [2020, 2021, 2022] ]\n",
    "\n",
    "games_df = pd.concat(dfs) \n",
    "print(f'starting with {len(games_df)} records on disk')\n",
    "\n",
    "## some cleanup stuff\n",
    "\n",
    "# first off, ditch rows without our target label\n",
    "rows_to_drop = games_df[games_df.pitch_type.isna()].index\n",
    "games_df.drop(rows_to_drop, inplace=True)\n",
    "\n",
    "# for now, let's make this a binary classifier. we can later try to predict specific pitches\n",
    "LABEL_COLUMN_NAME = \"is_fastball\"\n",
    "games_df[LABEL_COLUMN_NAME] = games_df.pitch_type.str.startswith('F').astype(float)\n",
    "print(f'target label breakdown\\n{games_df[LABEL_COLUMN_NAME].value_counts()}')\n",
    "\n",
    "# turn player ids on base into flags (dont want to bother embedding, too sparse)\n",
    "for col in [\"on_1b\", \"on_2b\", \"on_3b\"]:\n",
    "    games_df[col + \"_notna\"] = games_df[col].notna().astype(int)\n",
    "    games_df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# TODO figure out date as a categorical\n",
    "DAY_OF_YEAR = 'day_of_year'\n",
    "games_df[DAY_OF_YEAR] = games_df.game_date.dt.dayofyear\n",
    "\n",
    "# cast some types\n",
    "games_df = games_df.astype({\n",
    "    'pitcher': 'int', \n",
    "    'batter': 'int',\n",
    "}, errors='ignore')\n",
    "\n",
    "# here we capture the match-up -- just store the index from a map of combos\n",
    "matchups = pd.Series(zip(games_df.pitcher, games_df.batter))\n",
    "matchup_idx = {matchup:idx for idx, matchup in enumerate(matchups.unique())}\n",
    "MATCH_UP = 'matchup' # col name for reuse later\n",
    "games_df[MATCH_UP] = matchups.map(matchup_idx)\n",
    "\n",
    "# one last bit of info, the current lead at the time of the pitch\n",
    "PITCHER_LEAD = 'pitcher_lead'\n",
    "games_df[PITCHER_LEAD] = games_df.fld_score - games_df.bat_score\n",
    "\n",
    "\n",
    "# ok, ready to set up our dataset\n",
    "\n",
    "ds_meta = NormalizedClassifierDatasetMetadata(LABEL_COLUMN_NAME)\n",
    "ds_meta.set_ordinal_numeric_cols( [\n",
    "    \"inning\",\n",
    "    \"bat_score\", \n",
    "    \"fld_score\", \n",
    "    \"home_score\",\n",
    "    \"away_score\",\n",
    "    PITCHER_LEAD,\n",
    "    \"balls\", \n",
    "    \"strikes\", \n",
    "    \"outs_when_up\",   \n",
    "    DAY_OF_YEAR,\n",
    "    \"at_bat_number\",\n",
    "    \"pitch_number\",\n",
    "    \"n_thruorder_pitcher\",\n",
    "    \"age_pit\",\n",
    "    \"age_bat\",\n",
    "    \"pitcher_days_since_prev_game\",\n",
    "    MATCH_UP,\n",
    "] )\n",
    "\n",
    "# TODO make assertion that these columns dont have duplicates\n",
    "\n",
    "ds_meta.set_categorical_map({\n",
    "    col : list(games_df[col].unique()) for col in ['p_throws', 'stand']  #, 'if_fielding_alignment', 'of_fielding_alignment']\n",
    "})\n",
    "\n",
    "# make an embedding out of the matchup only\n",
    "# ds_meta.set_embedding_cols([MATCH_UP])\n",
    "\n",
    "target_df = games_df[ ds_meta.get_columns() ].dropna()\n",
    "overall_ds = NormalizedClassifierDataset(target_df, ds_meta)\n",
    "\n",
    "\n",
    "train_ds, test_ds = random_split(overall_ds, [.80, .20])\n",
    "\n",
    "batch_size = int(len(train_ds) / 20)\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "print(f'{len(train_ds)} batches with batch_size: {batch_size}, {len(test_ds)} batches for test.')\n",
    "num_features = overall_ds.get_feature_count()\n",
    "print(f'datasets have {num_features} features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dropoutRate = 0.2\n",
    "\n",
    "input_features = overall_ds.get_feature_count()\n",
    "model = GeneralNN( input_features, [num_features*2,num_features*2,16,16,1], dropoutRate )\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"The model has {total_params} parameters.\")\n",
    "\n",
    "training_mgr = TrainingManager(model)\n",
    "training_mgr.train(train_dataloader, 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91977d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mgr.eval(test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
